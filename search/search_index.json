{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>data-prep</li> <li>experiments<ul> <li>exp_20230614175606<ul> <li>data_generator</li> <li>evaluate</li> <li>find_lr</li> <li>metrics</li> <li>model<ul> <li>net</li> </ul> </li> <li>train</li> <li>utils</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/data-prep/","title":"Data preparation","text":"<p>Creation of well-named targets for statute prediction utilising data from the AILA 2019 track.</p>"},{"location":"reference/experiments/","title":"Experimentation","text":"<p>Code for baseline experiments to be used for the LLM Legal Prompt Engineering project.</p> <ul> <li>exp_20230614175606: Baseline experiment for statute prediction using LLMs.</li> </ul>"},{"location":"reference/experiments/exp_20230614175606/data_generator/","title":"data_generator","text":"<p>Data loader for BertMultiLabel</p>"},{"location":"reference/experiments/exp_20230614175606/data_generator/#src.experiments.exp_20230614175606.data_generator.BertMultiLabelDataset","title":"<code>BertMultiLabelDataset</code>","text":"<p>         Bases: <code>Dataset</code></p> Source code in <code>src/experiments/exp_20230614175606/data_generator.py</code> <pre><code>class BertMultiLabelDataset(Dataset):\n    def __init__(self, data_paths, targets_paths, unique_labels=None,\n                 mode=\"train\"):\n        self.data_paths = data_paths\n        self.targets_paths = targets_paths\n        self.targets_dict = self.get_targets()\n        if unique_labels is None:\n            self.unique_labels = self.get_unique_labels()\n        else:\n            with open(unique_labels, 'r') as f:\n                self.unique_labels = f.readlines()\n            self.unique_labels = list(filter(None, map(lambda x: x.strip(\"\\n\"),\n                                                       self.unique_labels)))\n\n        self.text_paths = self.get_fullpaths()\n        # IDs needed for __getitem__\n        self.idx = {i: k for i, k in enumerate(self.text_paths)}\n\n        self.mode = mode\n\n    def __len__(self):\n        return len(self.text_paths.keys())\n\n    def __getitem__(self, idx):\n        data = self.load_data(self.text_paths[self.idx[idx]])\n        target = self.fetch_target(self.idx[idx])\n\n        if self.mode == \"train\":\n            return data, target\n        else:\n            flname = os.path.splitext(os.path.basename(self.idx[idx]))[0]\n            return flname, data\n\n    def get_fullpaths(self):\n\n        doc_paths = {}\n        for path in self.data_paths:\n            for doc_idx in os.listdir(path):\n                idx = os.path.splitext(doc_idx)[0]\n                doc_paths[idx] = os.path.join(path, doc_idx)\n\n        return doc_paths\n\n    def get_targets(self) -&gt; dict:\n\"\"\"Get targets of documents from targets paths.\n\n        Returns\n        -------\n        targets: dict\n            Dictionary containing the targets of each document.\n        \"\"\"\n        targets = {}\n        for path in self.targets_paths:\n            with open(path, 'r') as f:\n                target = json.load(f)\n            targets.update(target)\n\n        return targets\n\n    def fetch_target(self, doc):\n\"\"\"Return target tensors for given batch\n\n        Parameters\n        ----------\n        batch : list\n            List of document IDs for a batch.\n\n        Returns\n        -------\n        targets : torch.nn.Tensor\n            Tensor containing the target tensors.\n        \"\"\"\n        target = torch.tensor([int(label in self.targets_dict.get(doc, []))\n                               for label in self.unique_labels])\n\n        return target\n\n    def load_data(self, path):\n        with open(path, 'r') as f:\n            data = f.read()\n        return data\n\n    def get_unique_labels(self):\n\n        # Keeping it as a list for ordering ??\n        unique_labels = list(set([label\n                                  for labels in self.targets_dict.values()\n                                  for label in labels]))\n\n        # Extra step to ensure consistency with test dataset\n        unique_labels = sorted(unique_labels)\n\n        return unique_labels\n</code></pre>"},{"location":"reference/experiments/exp_20230614175606/data_generator/#src.experiments.exp_20230614175606.data_generator.BertMultiLabelDataset.fetch_target","title":"<code>fetch_target(doc)</code>","text":"<p>Return target tensors for given batch</p>"},{"location":"reference/experiments/exp_20230614175606/data_generator/#src.experiments.exp_20230614175606.data_generator.BertMultiLabelDataset.fetch_target--parameters","title":"Parameters","text":"list <p>List of document IDs for a batch.</p>"},{"location":"reference/experiments/exp_20230614175606/data_generator/#src.experiments.exp_20230614175606.data_generator.BertMultiLabelDataset.fetch_target--returns","title":"Returns","text":"torch.nn.Tensor <p>Tensor containing the target tensors.</p> Source code in <code>src/experiments/exp_20230614175606/data_generator.py</code> <pre><code>def fetch_target(self, doc):\n\"\"\"Return target tensors for given batch\n\n    Parameters\n    ----------\n    batch : list\n        List of document IDs for a batch.\n\n    Returns\n    -------\n    targets : torch.nn.Tensor\n        Tensor containing the target tensors.\n    \"\"\"\n    target = torch.tensor([int(label in self.targets_dict.get(doc, []))\n                           for label in self.unique_labels])\n\n    return target\n</code></pre>"},{"location":"reference/experiments/exp_20230614175606/data_generator/#src.experiments.exp_20230614175606.data_generator.BertMultiLabelDataset.get_targets","title":"<code>get_targets()</code>","text":"<p>Get targets of documents from targets paths.</p>"},{"location":"reference/experiments/exp_20230614175606/data_generator/#src.experiments.exp_20230614175606.data_generator.BertMultiLabelDataset.get_targets--returns","title":"Returns","text":"dict <p>Dictionary containing the targets of each document.</p> Source code in <code>src/experiments/exp_20230614175606/data_generator.py</code> <pre><code>def get_targets(self) -&gt; dict:\n\"\"\"Get targets of documents from targets paths.\n\n    Returns\n    -------\n    targets: dict\n        Dictionary containing the targets of each document.\n    \"\"\"\n    targets = {}\n    for path in self.targets_paths:\n        with open(path, 'r') as f:\n            target = json.load(f)\n        targets.update(target)\n\n    return targets\n</code></pre>"},{"location":"reference/experiments/exp_20230614175606/evaluate/","title":"evaluate","text":"<p>Evaluation script for BertMultiLabel</p>"},{"location":"reference/experiments/exp_20230614175606/find_lr/","title":"find_lr","text":"<p>Training and evaluation for EnsembleSelfAttn</p>"},{"location":"reference/experiments/exp_20230614175606/metrics/","title":"metrics","text":"<p>Metrics to be calculated for the model.</p>"},{"location":"reference/experiments/exp_20230614175606/metrics/#src.experiments.exp_20230614175606.metrics.custom_f1","title":"<code>custom_f1(outputs_batch, targets_batch, target_names)</code>","text":"<p>Calculate per class and macro F1 between the given predictions and targets</p>"},{"location":"reference/experiments/exp_20230614175606/metrics/#src.experiments.exp_20230614175606.metrics.custom_f1--parameters","title":"Parameters","text":"MutableSequence <p>Predictions of a batch.</p> MutableSequence <p>Targets of the batch.</p> list[str] <p>Names of targets.</p>"},{"location":"reference/experiments/exp_20230614175606/metrics/#src.experiments.exp_20230614175606.metrics.custom_f1--returns","title":"Returns","text":"dict <p>Dictionary containing the metric values.</p> Source code in <code>src/experiments/exp_20230614175606/metrics.py</code> <pre><code>def custom_f1(outputs_batch: MutableSequence,\n              targets_batch: MutableSequence, target_names: list) -&gt; dict:\n\"\"\"Calculate per class and macro F1 between the given predictions\n    and targets\n\n    Parameters\n    ----------\n    outputs_batch : MutableSequence\n        Predictions of a batch.\n    targets_batch : MutableSequence\n        Targets of the batch.\n    target_names  : list[str]\n        Names of targets.\n\n    Returns\n    -------\n    scores : dict\n        Dictionary containing the metric values.\n\n    \"\"\"\n\n    per_class_prec = []\n    per_class_rec = []\n\n    num_classes = targets_batch.shape[-1]\n\n    for cls in range(num_classes):\n        tp = np.dot(targets_batch[:, cls], outputs_batch[:, cls])\n        pp = np.sum(outputs_batch[:, cls])\n        p = np.sum(targets_batch[:, cls])\n        prec = tp/pp if pp != 0 else 0\n        rec = tp/p if p != 0 else 0\n\n        per_class_prec.append(prec)\n        per_class_rec.append(rec)\n\n    den = [per_class_prec[i] + per_class_rec[i]\n           for i in range(len(per_class_rec))]\n    num = [2 * (per_class_prec[i] * per_class_rec[i])\n           for i in range(len(per_class_rec))]\n\n    per_class_f1 = [num_val * 1./den_val if den_val != 0 else 0\n                    for num_val, den_val in zip(num, den)]\n\n    macro_f1 = sum(per_class_f1) * 1./len(per_class_f1)\n\n    # Converting metrics to dictionaries for easier understanding\n    per_class_prec = {\n            k: per_class_prec[i] for i, k in enumerate(target_names)}\n    per_class_rec = {\n            k: per_class_rec[i] for i, k in enumerate(target_names)}\n    per_class_f1 = {\n            k: per_class_f1[i] for i, k in enumerate(target_names)}\n\n    scores = {\n        'precision': per_class_prec,\n        'recall': per_class_rec,\n        'f1': per_class_f1,\n        'macro_f1': macro_f1,\n        }\n\n    return scores\n</code></pre>"},{"location":"reference/experiments/exp_20230614175606/metrics/#src.experiments.exp_20230614175606.metrics.f1","title":"<code>f1(outputs_batch, targets_batch, target_names)</code>","text":"<p>Calculate per class and macro F1 between the given predictions and targets</p>"},{"location":"reference/experiments/exp_20230614175606/metrics/#src.experiments.exp_20230614175606.metrics.f1--parameters","title":"Parameters","text":"MutableSequence <p>Predictions of a batch.</p> MutableSequence <p>Targets of the batch.</p> list[str] <p>Names of targets.</p>"},{"location":"reference/experiments/exp_20230614175606/metrics/#src.experiments.exp_20230614175606.metrics.f1--returns","title":"Returns","text":"dict <p>Dictionary containing the metric values.</p> Source code in <code>src/experiments/exp_20230614175606/metrics.py</code> <pre><code>def f1(outputs_batch: MutableSequence,\n       targets_batch: MutableSequence, target_names: list) -&gt; dict:\n\"\"\"Calculate per class and macro F1 between the given predictions\n    and targets\n\n    Parameters\n    ----------\n    outputs_batch : MutableSequence\n        Predictions of a batch.\n    targets_batch : MutableSequence\n        Targets of the batch.\n    target_names  : list[str]\n        Names of targets.\n\n    Returns\n    -------\n    scores : dict\n        Dictionary containing the metric values.\n\n    \"\"\"\n    class_metrics = prfs(targets_batch, outputs_batch, average=None)\n    per_class_prec, per_class_rec, per_class_f1, per_class_sup = class_metrics\n\n    macro_metrics = prfs(targets_batch, outputs_batch, average='macro')\n    macro_prec, macro_rec, macro_f1, macro_sup = macro_metrics\n\n    micro_metrics = prfs(targets_batch, outputs_batch, average='micro')\n    micro_prec, micro_rec, micro_f1, micro_sup = micro_metrics\n\n    # Converting metrics to dictionaries for easier understanding\n    per_class_prec = {\n            k: float(per_class_prec[i]) for i, k in enumerate(target_names)}\n    per_class_rec = {\n            k: float(per_class_rec[i]) for i, k in enumerate(target_names)}\n    per_class_f1 = {\n            k: float(per_class_f1[i]) for i, k in enumerate(target_names)}\n    per_class_sup = {\n            k: float(per_class_sup[i]) for i, k in enumerate(target_names)}\n\n    scores = {\n        'precision': per_class_prec,\n        'recall': per_class_rec,\n        'f1': per_class_f1,\n        'sup': per_class_sup,\n        'macro_prec': float(macro_prec) if macro_prec is not None else macro_prec,\n        'macro_rec': float(macro_rec) if macro_rec is not None else macro_rec,\n        'macro_f1': float(macro_f1) if macro_f1 is not None else macro_f1,\n        'macro_sup': float(macro_sup) if macro_sup is not None else macro_sup,\n        'micro_prec': float(micro_prec) if micro_prec is not None else micro_prec,\n        'micro_rec': float(micro_rec) if micro_rec is not None else micro_rec,\n        'micro_f1': float(micro_f1) if micro_f1 is not None else micro_f1,\n        'micro_sup': float(micro_sup) if micro_sup is not None else micro_sup,\n        }\n\n    return scores\n</code></pre>"},{"location":"reference/experiments/exp_20230614175606/train/","title":"train","text":"<p>Training and evaluation for BertMultiLabel</p>"},{"location":"reference/experiments/exp_20230614175606/utils/","title":"utils","text":"<p>Utilities for BertMultiLabel</p>"},{"location":"reference/experiments/exp_20230614175606/utils/#src.experiments.exp_20230614175606.utils.Accumulate","title":"<code>Accumulate</code>","text":"<p>Maintain all data used in an epoch for metrics calculation.</p> Source code in <code>src/experiments/exp_20230614175606/utils.py</code> <pre><code>class Accumulate:\n\"\"\"Maintain all data used in an epoch for metrics calculation.\"\"\"\n\n    def __init__(self):\n        self.output_batch = []\n        self.targets_batch = []\n\n    def update(self, output_batch, targets_batch):\n        self.output_batch.extend(output_batch.tolist())\n        self.targets_batch.extend(targets_batch.tolist())\n\n    def __call__(self):\n\n        return (np.stack(self.output_batch, axis=0),\n                np.stack(self.targets_batch, axis=0))\n</code></pre>"},{"location":"reference/experiments/exp_20230614175606/utils/#src.experiments.exp_20230614175606.utils.Params","title":"<code>Params</code>","text":"<p>Class that loads hyperparameters from a json file.</p> Source code in <code>src/experiments/exp_20230614175606/utils.py</code> <pre><code>class Params:\n\"\"\"Class that loads hyperparameters from a json file.\"\"\"\n\n    def __init__(self, json_path):\n        with open(json_path, 'r') as f:\n            params = json.load(f)\n            self.__dict__.update(params)\n\n    def save(self, json_path):\n        with open(json_path, 'w') as f:\n            json.dump(self.__dict__, f, indent=4)\n\n    @property\n    def dict(self):\n\"\"\"Provide dictionary-like access to hyperparameters.\"\"\"\n        return self.__dict__\n</code></pre>"},{"location":"reference/experiments/exp_20230614175606/utils/#src.experiments.exp_20230614175606.utils.Params.dict","title":"<code>dict</code>  <code>property</code>","text":"<p>Provide dictionary-like access to hyperparameters.</p>"},{"location":"reference/experiments/exp_20230614175606/model/net/","title":"net","text":"<p>BERT-based model for multi-label classification.</p>"},{"location":"reference/experiments/exp_20230614175606/model/net/#src.experiments.exp_20230614175606.model.net.BertMultiLabel","title":"<code>BertMultiLabel</code>","text":"<p>         Bases: <code>nn.Module</code></p> <p>Auto-based model for multi-label classification</p> Source code in <code>src/experiments/exp_20230614175606/model/net.py</code> <pre><code>class BertMultiLabel(nn.Module):\n\n\"\"\"Auto-based model for multi-label classification\"\"\"\n\n    def __init__(self, labels, device, hidden_size=768, max_length=4096,\n                 model_name=\"allenai/longformer-base-4096\",\n                 truncation_side=\"right\", mode=\"train\"):\n        super(BertMultiLabel, self).__init__()\n        self.hidden_size = hidden_size\n        self.device = device\n        self.max_length = max_length\n        self.labels = [re.sub(r'[^A-Za-z]', '', label)\n                       for label in labels]\n        self.model_name = model_name\n        self.model = AutoModel.from_pretrained(self.model_name)\n        self.truncation_side = truncation_side\n        self.mode = mode\n        # Keeping the tokenizer here makes the model better behaved\n        # as opposed to using it in the DataLoader\n        self.tokenizer = AutoTokenizer.from_pretrained(\n                                        self.model_name,\n                                        truncation_side=self.truncation_side)\n\n        self.prediction = nn.ModuleDict({\n            k: nn.Linear(in_features=self.hidden_size,\n                         out_features=1,\n                         bias=True,)\n            for k in self.labels})\n\n    def process(self, x):\n        tokenized = self.tokenizer(x, truncation=True, padding=\"longest\",\n                                              max_length=self.max_length,\n                                              return_tensors=\"pt\")\n        return tokenized\n\n    def forward(self, x):\n        tokenized = self.process(x)\n        tokenized = tokenized.to(self.device)\n        preds = torch.tensor([])\n        preds = preds.to(self.device)\n\n        encoding = self.model(**tokenized)\n        # Retaining only the [CLS] token\n        cls = encoding.last_hidden_state[:, 0, :]\n        m = nn.Sigmoid()\n        for label in self.labels:\n            pred = self.prediction[label](cls)\n            preds = torch.cat((preds, pred), dim=-1)\n\n        preds = m(preds)\n        if self.mode == \"train\":\n            return preds\n        else:\n            return preds, cls\n</code></pre>"}]}